{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge: model comparison\n",
    "\n",
    "Find a data set and build a KNN Regression and an OLS regression. Compare the two. How similar are they?\n",
    "\n",
    "For this challenge, we will be using the [Avocado Prices](https://www.kaggle.com/neuromusic/avocado-prices/downloads/avocado-prices.zip/1) dataset, containing historical data on avocado prices and sales volume in multiple US markets. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries:\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Date</th>\n",
       "      <th>AveragePrice</th>\n",
       "      <th>Total Volume</th>\n",
       "      <th>4046</th>\n",
       "      <th>4225</th>\n",
       "      <th>4770</th>\n",
       "      <th>Total Bags</th>\n",
       "      <th>Small Bags</th>\n",
       "      <th>Large Bags</th>\n",
       "      <th>XLarge Bags</th>\n",
       "      <th>type</th>\n",
       "      <th>year</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2015-12-27</td>\n",
       "      <td>1.33</td>\n",
       "      <td>64236.62</td>\n",
       "      <td>1036.74</td>\n",
       "      <td>54454.85</td>\n",
       "      <td>48.16</td>\n",
       "      <td>8696.87</td>\n",
       "      <td>8603.62</td>\n",
       "      <td>93.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-12-20</td>\n",
       "      <td>1.35</td>\n",
       "      <td>54876.98</td>\n",
       "      <td>674.28</td>\n",
       "      <td>44638.81</td>\n",
       "      <td>58.33</td>\n",
       "      <td>9505.56</td>\n",
       "      <td>9408.07</td>\n",
       "      <td>97.49</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2015-12-13</td>\n",
       "      <td>0.93</td>\n",
       "      <td>118220.22</td>\n",
       "      <td>794.70</td>\n",
       "      <td>109149.67</td>\n",
       "      <td>130.50</td>\n",
       "      <td>8145.35</td>\n",
       "      <td>8042.21</td>\n",
       "      <td>103.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2015-12-06</td>\n",
       "      <td>1.08</td>\n",
       "      <td>78992.15</td>\n",
       "      <td>1132.00</td>\n",
       "      <td>71976.41</td>\n",
       "      <td>72.58</td>\n",
       "      <td>5811.16</td>\n",
       "      <td>5677.40</td>\n",
       "      <td>133.76</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2015-11-29</td>\n",
       "      <td>1.28</td>\n",
       "      <td>51039.60</td>\n",
       "      <td>941.48</td>\n",
       "      <td>43838.39</td>\n",
       "      <td>75.78</td>\n",
       "      <td>6183.95</td>\n",
       "      <td>5986.26</td>\n",
       "      <td>197.69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        Date  AveragePrice  Total Volume     4046       4225  \\\n",
       "0           0  2015-12-27          1.33      64236.62  1036.74   54454.85   \n",
       "1           1  2015-12-20          1.35      54876.98   674.28   44638.81   \n",
       "2           2  2015-12-13          0.93     118220.22   794.70  109149.67   \n",
       "3           3  2015-12-06          1.08      78992.15  1132.00   71976.41   \n",
       "4           4  2015-11-29          1.28      51039.60   941.48   43838.39   \n",
       "\n",
       "     4770  Total Bags  Small Bags  Large Bags  XLarge Bags          type  \\\n",
       "0   48.16     8696.87     8603.62       93.25          0.0  conventional   \n",
       "1   58.33     9505.56     9408.07       97.49          0.0  conventional   \n",
       "2  130.50     8145.35     8042.21      103.14          0.0  conventional   \n",
       "3   72.58     5811.16     5677.40      133.76          0.0  conventional   \n",
       "4   75.78     6183.95     5986.26      197.69          0.0  conventional   \n",
       "\n",
       "   year  region  \n",
       "0  2015  Albany  \n",
       "1  2015  Albany  \n",
       "2  2015  Albany  \n",
       "3  2015  Albany  \n",
       "4  2015  Albany  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avocado = pd.read_csv('avocado.csv')\n",
    "avocado.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18249 entries, 0 to 18248\n",
      "Data columns (total 14 columns):\n",
      "Unnamed: 0      18249 non-null int64\n",
      "Date            18249 non-null object\n",
      "AveragePrice    18249 non-null float64\n",
      "Total Volume    18249 non-null float64\n",
      "4046            18249 non-null float64\n",
      "4225            18249 non-null float64\n",
      "4770            18249 non-null float64\n",
      "Total Bags      18249 non-null float64\n",
      "Small Bags      18249 non-null float64\n",
      "Large Bags      18249 non-null float64\n",
      "XLarge Bags     18249 non-null float64\n",
      "type            18249 non-null object\n",
      "year            18249 non-null int64\n",
      "region          18249 non-null object\n",
      "dtypes: float64(9), int64(2), object(3)\n",
      "memory usage: 1.9+ MB\n"
     ]
    }
   ],
   "source": [
    "avocado.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>AveragePrice</th>\n",
       "      <th>Total Volume</th>\n",
       "      <th>4046</th>\n",
       "      <th>4225</th>\n",
       "      <th>4770</th>\n",
       "      <th>Total Bags</th>\n",
       "      <th>Small Bags</th>\n",
       "      <th>Large Bags</th>\n",
       "      <th>XLarge Bags</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>18249.000000</td>\n",
       "      <td>18249.000000</td>\n",
       "      <td>1.824900e+04</td>\n",
       "      <td>1.824900e+04</td>\n",
       "      <td>1.824900e+04</td>\n",
       "      <td>1.824900e+04</td>\n",
       "      <td>1.824900e+04</td>\n",
       "      <td>1.824900e+04</td>\n",
       "      <td>1.824900e+04</td>\n",
       "      <td>18249.000000</td>\n",
       "      <td>18249.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>24.232232</td>\n",
       "      <td>1.405978</td>\n",
       "      <td>8.506440e+05</td>\n",
       "      <td>2.930084e+05</td>\n",
       "      <td>2.951546e+05</td>\n",
       "      <td>2.283974e+04</td>\n",
       "      <td>2.396392e+05</td>\n",
       "      <td>1.821947e+05</td>\n",
       "      <td>5.433809e+04</td>\n",
       "      <td>3106.426507</td>\n",
       "      <td>2016.147899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>15.481045</td>\n",
       "      <td>0.402677</td>\n",
       "      <td>3.453545e+06</td>\n",
       "      <td>1.264989e+06</td>\n",
       "      <td>1.204120e+06</td>\n",
       "      <td>1.074641e+05</td>\n",
       "      <td>9.862424e+05</td>\n",
       "      <td>7.461785e+05</td>\n",
       "      <td>2.439660e+05</td>\n",
       "      <td>17692.894652</td>\n",
       "      <td>0.939938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.440000</td>\n",
       "      <td>8.456000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2015.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>1.083858e+04</td>\n",
       "      <td>8.540700e+02</td>\n",
       "      <td>3.008780e+03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.088640e+03</td>\n",
       "      <td>2.849420e+03</td>\n",
       "      <td>1.274700e+02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2015.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>24.000000</td>\n",
       "      <td>1.370000</td>\n",
       "      <td>1.073768e+05</td>\n",
       "      <td>8.645300e+03</td>\n",
       "      <td>2.906102e+04</td>\n",
       "      <td>1.849900e+02</td>\n",
       "      <td>3.974383e+04</td>\n",
       "      <td>2.636282e+04</td>\n",
       "      <td>2.647710e+03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2016.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.660000</td>\n",
       "      <td>4.329623e+05</td>\n",
       "      <td>1.110202e+05</td>\n",
       "      <td>1.502069e+05</td>\n",
       "      <td>6.243420e+03</td>\n",
       "      <td>1.107834e+05</td>\n",
       "      <td>8.333767e+04</td>\n",
       "      <td>2.202925e+04</td>\n",
       "      <td>132.500000</td>\n",
       "      <td>2017.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>52.000000</td>\n",
       "      <td>3.250000</td>\n",
       "      <td>6.250565e+07</td>\n",
       "      <td>2.274362e+07</td>\n",
       "      <td>2.047057e+07</td>\n",
       "      <td>2.546439e+06</td>\n",
       "      <td>1.937313e+07</td>\n",
       "      <td>1.338459e+07</td>\n",
       "      <td>5.719097e+06</td>\n",
       "      <td>551693.650000</td>\n",
       "      <td>2018.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0  AveragePrice  Total Volume          4046          4225  \\\n",
       "count  18249.000000  18249.000000  1.824900e+04  1.824900e+04  1.824900e+04   \n",
       "mean      24.232232      1.405978  8.506440e+05  2.930084e+05  2.951546e+05   \n",
       "std       15.481045      0.402677  3.453545e+06  1.264989e+06  1.204120e+06   \n",
       "min        0.000000      0.440000  8.456000e+01  0.000000e+00  0.000000e+00   \n",
       "25%       10.000000      1.100000  1.083858e+04  8.540700e+02  3.008780e+03   \n",
       "50%       24.000000      1.370000  1.073768e+05  8.645300e+03  2.906102e+04   \n",
       "75%       38.000000      1.660000  4.329623e+05  1.110202e+05  1.502069e+05   \n",
       "max       52.000000      3.250000  6.250565e+07  2.274362e+07  2.047057e+07   \n",
       "\n",
       "               4770    Total Bags    Small Bags    Large Bags    XLarge Bags  \\\n",
       "count  1.824900e+04  1.824900e+04  1.824900e+04  1.824900e+04   18249.000000   \n",
       "mean   2.283974e+04  2.396392e+05  1.821947e+05  5.433809e+04    3106.426507   \n",
       "std    1.074641e+05  9.862424e+05  7.461785e+05  2.439660e+05   17692.894652   \n",
       "min    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00       0.000000   \n",
       "25%    0.000000e+00  5.088640e+03  2.849420e+03  1.274700e+02       0.000000   \n",
       "50%    1.849900e+02  3.974383e+04  2.636282e+04  2.647710e+03       0.000000   \n",
       "75%    6.243420e+03  1.107834e+05  8.333767e+04  2.202925e+04     132.500000   \n",
       "max    2.546439e+06  1.937313e+07  1.338459e+07  5.719097e+06  551693.650000   \n",
       "\n",
       "               year  \n",
       "count  18249.000000  \n",
       "mean    2016.147899  \n",
       "std        0.939938  \n",
       "min     2015.000000  \n",
       "25%     2015.000000  \n",
       "50%     2016.000000  \n",
       "75%     2017.000000  \n",
       "max     2018.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avocado.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0      0\n",
       "Date            0\n",
       "AveragePrice    0\n",
       "Total Volume    0\n",
       "4046            0\n",
       "4225            0\n",
       "4770            0\n",
       "Total Bags      0\n",
       "Small Bags      0\n",
       "Large Bags      0\n",
       "XLarge Bags     0\n",
       "type            0\n",
       "year            0\n",
       "region          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avocado.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to do some feature processing, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No missing values, nice!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(avocado.corr())\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The features look extremely correlated with each other...is this a potential issue in modeling?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Date</th>\n",
       "      <th>AveragePrice</th>\n",
       "      <th>Total Volume</th>\n",
       "      <th>4046</th>\n",
       "      <th>4225</th>\n",
       "      <th>4770</th>\n",
       "      <th>Total Bags</th>\n",
       "      <th>Small Bags</th>\n",
       "      <th>Large Bags</th>\n",
       "      <th>XLarge Bags</th>\n",
       "      <th>type</th>\n",
       "      <th>year</th>\n",
       "      <th>region</th>\n",
       "      <th>Month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2015-12-27</td>\n",
       "      <td>1.33</td>\n",
       "      <td>64236.62</td>\n",
       "      <td>1036.74</td>\n",
       "      <td>54454.85</td>\n",
       "      <td>48.16</td>\n",
       "      <td>8696.87</td>\n",
       "      <td>8603.62</td>\n",
       "      <td>93.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-12-20</td>\n",
       "      <td>1.35</td>\n",
       "      <td>54876.98</td>\n",
       "      <td>674.28</td>\n",
       "      <td>44638.81</td>\n",
       "      <td>58.33</td>\n",
       "      <td>9505.56</td>\n",
       "      <td>9408.07</td>\n",
       "      <td>97.49</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2015-12-13</td>\n",
       "      <td>0.93</td>\n",
       "      <td>118220.22</td>\n",
       "      <td>794.70</td>\n",
       "      <td>109149.67</td>\n",
       "      <td>130.50</td>\n",
       "      <td>8145.35</td>\n",
       "      <td>8042.21</td>\n",
       "      <td>103.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2015-12-06</td>\n",
       "      <td>1.08</td>\n",
       "      <td>78992.15</td>\n",
       "      <td>1132.00</td>\n",
       "      <td>71976.41</td>\n",
       "      <td>72.58</td>\n",
       "      <td>5811.16</td>\n",
       "      <td>5677.40</td>\n",
       "      <td>133.76</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2015-11-29</td>\n",
       "      <td>1.28</td>\n",
       "      <td>51039.60</td>\n",
       "      <td>941.48</td>\n",
       "      <td>43838.39</td>\n",
       "      <td>75.78</td>\n",
       "      <td>6183.95</td>\n",
       "      <td>5986.26</td>\n",
       "      <td>197.69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0       Date  AveragePrice  Total Volume     4046       4225  \\\n",
       "0           0 2015-12-27          1.33      64236.62  1036.74   54454.85   \n",
       "1           1 2015-12-20          1.35      54876.98   674.28   44638.81   \n",
       "2           2 2015-12-13          0.93     118220.22   794.70  109149.67   \n",
       "3           3 2015-12-06          1.08      78992.15  1132.00   71976.41   \n",
       "4           4 2015-11-29          1.28      51039.60   941.48   43838.39   \n",
       "\n",
       "     4770  Total Bags  Small Bags  Large Bags  XLarge Bags          type  \\\n",
       "0   48.16     8696.87     8603.62       93.25          0.0  conventional   \n",
       "1   58.33     9505.56     9408.07       97.49          0.0  conventional   \n",
       "2  130.50     8145.35     8042.21      103.14          0.0  conventional   \n",
       "3   72.58     5811.16     5677.40      133.76          0.0  conventional   \n",
       "4   75.78     6183.95     5986.26      197.69          0.0  conventional   \n",
       "\n",
       "   year  region  Month  \n",
       "0  2015  Albany     12  \n",
       "1  2015  Albany     12  \n",
       "2  2015  Albany     12  \n",
       "3  2015  Albany     12  \n",
       "4  2015  Albany     11  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# label encoding categorical features:\n",
    "categorical = avocado.dtypes[avocado.dtypes == 'object'].index\n",
    "avocado['Date'] = pd.to_datetime(avocado.Date)\n",
    "avocado['Month'] = avocado.Date.dt.month\n",
    "avocado.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "del avocado['Unnamed: 0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# One-hot encoding categorical variables:\n",
    "\n",
    "avocado = pd.concat([avocado, pd.get_dummies(avocado.type, prefix='type')], axis=1)\n",
    "avocado = pd.concat([avocado, pd.get_dummies(avocado.region, prefix='region',)], axis=1)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18249 entries, 0 to 18248\n",
      "Data columns (total 70 columns):\n",
      "Date                          18249 non-null datetime64[ns]\n",
      "AveragePrice                  18249 non-null float64\n",
      "Total Volume                  18249 non-null float64\n",
      "4046                          18249 non-null float64\n",
      "4225                          18249 non-null float64\n",
      "4770                          18249 non-null float64\n",
      "Total Bags                    18249 non-null float64\n",
      "Small Bags                    18249 non-null float64\n",
      "Large Bags                    18249 non-null float64\n",
      "XLarge Bags                   18249 non-null float64\n",
      "type                          18249 non-null object\n",
      "year                          18249 non-null int64\n",
      "region                        18249 non-null object\n",
      "Month                         18249 non-null int64\n",
      "type_conventional             18249 non-null uint8\n",
      "type_organic                  18249 non-null uint8\n",
      "region_Albany                 18249 non-null uint8\n",
      "region_Atlanta                18249 non-null uint8\n",
      "region_BaltimoreWashington    18249 non-null uint8\n",
      "region_Boise                  18249 non-null uint8\n",
      "region_Boston                 18249 non-null uint8\n",
      "region_BuffaloRochester       18249 non-null uint8\n",
      "region_California             18249 non-null uint8\n",
      "region_Charlotte              18249 non-null uint8\n",
      "region_Chicago                18249 non-null uint8\n",
      "region_CincinnatiDayton       18249 non-null uint8\n",
      "region_Columbus               18249 non-null uint8\n",
      "region_DallasFtWorth          18249 non-null uint8\n",
      "region_Denver                 18249 non-null uint8\n",
      "region_Detroit                18249 non-null uint8\n",
      "region_GrandRapids            18249 non-null uint8\n",
      "region_GreatLakes             18249 non-null uint8\n",
      "region_HarrisburgScranton     18249 non-null uint8\n",
      "region_HartfordSpringfield    18249 non-null uint8\n",
      "region_Houston                18249 non-null uint8\n",
      "region_Indianapolis           18249 non-null uint8\n",
      "region_Jacksonville           18249 non-null uint8\n",
      "region_LasVegas               18249 non-null uint8\n",
      "region_LosAngeles             18249 non-null uint8\n",
      "region_Louisville             18249 non-null uint8\n",
      "region_MiamiFtLauderdale      18249 non-null uint8\n",
      "region_Midsouth               18249 non-null uint8\n",
      "region_Nashville              18249 non-null uint8\n",
      "region_NewOrleansMobile       18249 non-null uint8\n",
      "region_NewYork                18249 non-null uint8\n",
      "region_Northeast              18249 non-null uint8\n",
      "region_NorthernNewEngland     18249 non-null uint8\n",
      "region_Orlando                18249 non-null uint8\n",
      "region_Philadelphia           18249 non-null uint8\n",
      "region_PhoenixTucson          18249 non-null uint8\n",
      "region_Pittsburgh             18249 non-null uint8\n",
      "region_Plains                 18249 non-null uint8\n",
      "region_Portland               18249 non-null uint8\n",
      "region_RaleighGreensboro      18249 non-null uint8\n",
      "region_RichmondNorfolk        18249 non-null uint8\n",
      "region_Roanoke                18249 non-null uint8\n",
      "region_Sacramento             18249 non-null uint8\n",
      "region_SanDiego               18249 non-null uint8\n",
      "region_SanFrancisco           18249 non-null uint8\n",
      "region_Seattle                18249 non-null uint8\n",
      "region_SouthCarolina          18249 non-null uint8\n",
      "region_SouthCentral           18249 non-null uint8\n",
      "region_Southeast              18249 non-null uint8\n",
      "region_Spokane                18249 non-null uint8\n",
      "region_StLouis                18249 non-null uint8\n",
      "region_Syracuse               18249 non-null uint8\n",
      "region_Tampa                  18249 non-null uint8\n",
      "region_TotalUS                18249 non-null uint8\n",
      "region_West                   18249 non-null uint8\n",
      "region_WestTexNewMexico       18249 non-null uint8\n",
      "dtypes: datetime64[ns](1), float64(9), int64(2), object(2), uint8(56)\n",
      "memory usage: 2.9+ MB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "avocado.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['AveragePrice', 'type_organic', 'type_conventional', '4046',\n",
       "       'Total Volume', '4770', 'Total Bags', 'Small Bags', 'Large Bags',\n",
       "       '4225', 'Month', 'region_HartfordSpringfield', 'region_SanFrancisco',\n",
       "       'region_Houston', 'XLarge Bags', 'region_NewYork',\n",
       "       'region_DallasFtWorth', 'region_SouthCentral', 'year',\n",
       "       'region_Philadelphia'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the top 20 most correlated features to our target, AveragePrice:\n",
    "np.abs(avocado.corr().loc[:,'AveragePrice']).sort_values(ascending=False).head(20).index\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>AveragePrice</th>\n",
       "      <th>Total Volume</th>\n",
       "      <th>4046</th>\n",
       "      <th>4225</th>\n",
       "      <th>4770</th>\n",
       "      <th>Total Bags</th>\n",
       "      <th>Small Bags</th>\n",
       "      <th>Large Bags</th>\n",
       "      <th>XLarge Bags</th>\n",
       "      <th>...</th>\n",
       "      <th>region_SouthCarolina</th>\n",
       "      <th>region_SouthCentral</th>\n",
       "      <th>region_Southeast</th>\n",
       "      <th>region_Spokane</th>\n",
       "      <th>region_StLouis</th>\n",
       "      <th>region_Syracuse</th>\n",
       "      <th>region_Tampa</th>\n",
       "      <th>region_TotalUS</th>\n",
       "      <th>region_West</th>\n",
       "      <th>region_WestTexNewMexico</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-12-27</td>\n",
       "      <td>1.33</td>\n",
       "      <td>64236.62</td>\n",
       "      <td>1036.74</td>\n",
       "      <td>54454.85</td>\n",
       "      <td>48.16</td>\n",
       "      <td>8696.87</td>\n",
       "      <td>8603.62</td>\n",
       "      <td>93.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-12-20</td>\n",
       "      <td>1.35</td>\n",
       "      <td>54876.98</td>\n",
       "      <td>674.28</td>\n",
       "      <td>44638.81</td>\n",
       "      <td>58.33</td>\n",
       "      <td>9505.56</td>\n",
       "      <td>9408.07</td>\n",
       "      <td>97.49</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-12-13</td>\n",
       "      <td>0.93</td>\n",
       "      <td>118220.22</td>\n",
       "      <td>794.70</td>\n",
       "      <td>109149.67</td>\n",
       "      <td>130.50</td>\n",
       "      <td>8145.35</td>\n",
       "      <td>8042.21</td>\n",
       "      <td>103.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-12-06</td>\n",
       "      <td>1.08</td>\n",
       "      <td>78992.15</td>\n",
       "      <td>1132.00</td>\n",
       "      <td>71976.41</td>\n",
       "      <td>72.58</td>\n",
       "      <td>5811.16</td>\n",
       "      <td>5677.40</td>\n",
       "      <td>133.76</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-11-29</td>\n",
       "      <td>1.28</td>\n",
       "      <td>51039.60</td>\n",
       "      <td>941.48</td>\n",
       "      <td>43838.39</td>\n",
       "      <td>75.78</td>\n",
       "      <td>6183.95</td>\n",
       "      <td>5986.26</td>\n",
       "      <td>197.69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date  AveragePrice  Total Volume     4046       4225    4770  \\\n",
       "0 2015-12-27          1.33      64236.62  1036.74   54454.85   48.16   \n",
       "1 2015-12-20          1.35      54876.98   674.28   44638.81   58.33   \n",
       "2 2015-12-13          0.93     118220.22   794.70  109149.67  130.50   \n",
       "3 2015-12-06          1.08      78992.15  1132.00   71976.41   72.58   \n",
       "4 2015-11-29          1.28      51039.60   941.48   43838.39   75.78   \n",
       "\n",
       "   Total Bags  Small Bags  Large Bags  XLarge Bags  ... region_SouthCarolina  \\\n",
       "0     8696.87     8603.62       93.25          0.0  ...                    0   \n",
       "1     9505.56     9408.07       97.49          0.0  ...                    0   \n",
       "2     8145.35     8042.21      103.14          0.0  ...                    0   \n",
       "3     5811.16     5677.40      133.76          0.0  ...                    0   \n",
       "4     6183.95     5986.26      197.69          0.0  ...                    0   \n",
       "\n",
       "   region_SouthCentral region_Southeast  region_Spokane  region_StLouis  \\\n",
       "0                    0                0               0               0   \n",
       "1                    0                0               0               0   \n",
       "2                    0                0               0               0   \n",
       "3                    0                0               0               0   \n",
       "4                    0                0               0               0   \n",
       "\n",
       "   region_Syracuse  region_Tampa  region_TotalUS  region_West  \\\n",
       "0                0             0               0            0   \n",
       "1                0             0               0            0   \n",
       "2                0             0               0            0   \n",
       "3                0             0               0            0   \n",
       "4                0             0               0            0   \n",
       "\n",
       "   region_WestTexNewMexico  \n",
       "0                        0  \n",
       "1                        0  \n",
       "2                        0  \n",
       "3                        0  \n",
       "4                        0  \n",
       "\n",
       "[5 rows x 70 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "avocado.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, an unweighted approach to the KNN Regressor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "avocado.fillna(0, inplace=True)\n",
    "#Feature set:\n",
    "X = avocado[['type_organic', 'type_conventional', '4046',\n",
    "       'Total Volume', '4770', 'Total Bags', 'Small Bags', 'Large Bags',\n",
    "       '4225', 'Month', 'region_HartfordSpringfield', 'region_SanFrancisco',\n",
    "       'region_Houston', 'XLarge Bags', 'region_NewYork',\n",
    "       'region_DallasFtWorth', 'region_SouthCentral', 'year',\n",
    "       'region_Philadelphia']]\n",
    "\n",
    "\n",
    "#Target:\n",
    "Y = avocado.AveragePrice\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Creating a train/test data split:\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.3, random_state = 465)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the regression scores of an unweighted KNN Regressor. \n",
    "We are using a holdout-group method to evaluate the model's accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ************** Unweighted holdout group testing *********** \n",
      "\n",
      "For k = 1, the KNN Regression score is: 0.4906292935439832\n",
      "For k = 2, the KNN Regression score is: 0.6107346748959095\n",
      "For k = 3, the KNN Regression score is: 0.6437163339873894\n",
      "For k = 4, the KNN Regression score is: 0.6595782424797427\n",
      "For k = 5, the KNN Regression score is: 0.664578483269533\n",
      "For k = 6, the KNN Regression score is: 0.6647143421091717\n",
      "For k = 7, the KNN Regression score is: 0.6642941746401461\n",
      "For k = 8, the KNN Regression score is: 0.6618339754786124\n",
      "For k = 9, the KNN Regression score is: 0.661897066541212\n",
      "For k = 10, the KNN Regression score is: 0.6582657403504066\n",
      "For k = 11, the KNN Regression score is: 0.6563473597238744\n",
      "For k = 12, the KNN Regression score is: 0.6541524413582954\n",
      "For k = 13, the KNN Regression score is: 0.6515038381635558\n",
      "For k = 14, the KNN Regression score is: 0.6487157632062293\n",
      "For k = 15, the KNN Regression score is: 0.6463276248995953\n",
      "For k = 16, the KNN Regression score is: 0.6448601897334894\n",
      "For k = 17, the KNN Regression score is: 0.6412792045419654\n",
      "For k = 18, the KNN Regression score is: 0.6388475476647439\n",
      "For k = 19, the KNN Regression score is: 0.6372863556260733\n",
      "\n",
      " (Unweighted) The best k value = 6, with a score of 0.6647143421091717 \n",
      "\n",
      "\n",
      " ************** Weighted holdout group testing *********** \n",
      "\n",
      "For k = 1, the KNN Regression score is: 0.4906292935439832\n",
      "For k = 2, the KNN Regression score is: 0.61336688846282\n",
      "For k = 3, the KNN Regression score is: 0.6490097562058974\n",
      "For k = 4, the KNN Regression score is: 0.6655273684686766\n",
      "For k = 5, the KNN Regression score is: 0.673328918200303\n",
      "For k = 6, the KNN Regression score is: 0.6757294306457213\n",
      "For k = 7, the KNN Regression score is: 0.676865199579203\n",
      "For k = 8, the KNN Regression score is: 0.6766842091601079\n",
      "For k = 9, the KNN Regression score is: 0.6771824919045955\n",
      "For k = 10, the KNN Regression score is: 0.6752112616790074\n",
      "For k = 11, the KNN Regression score is: 0.6745376790455351\n",
      "For k = 12, the KNN Regression score is: 0.67366888608269\n",
      "For k = 13, the KNN Regression score is: 0.6727311808208284\n",
      "For k = 14, the KNN Regression score is: 0.6710391281934498\n",
      "For k = 15, the KNN Regression score is: 0.669614360830892\n",
      "For k = 16, the KNN Regression score is: 0.6687085999656829\n",
      "For k = 17, the KNN Regression score is: 0.6664419404499291\n",
      "For k = 18, the KNN Regression score is: 0.6648502715285323\n",
      "For k = 19, the KNN Regression score is: 0.6637227178814256\n",
      "\n",
      " (Weighted) The best k value = 9, with a score of 0.6771824919045955\n"
     ]
    }
   ],
   "source": [
    "# Unweighted holdout group testing:\n",
    "print(\"\\n ************** Unweighted holdout group testing *********** \\n\")\n",
    "from sklearn.neighbors import KNeighborsRegressor \n",
    "holdout_scores=[] \n",
    "for k in range(1, 20):\n",
    "    knn = KNeighborsRegressor(n_neighbors=k)\n",
    "    knn.fit(X_train,y_train)\n",
    "    y_pred= knn.predict(X_test)\n",
    "    holdout_scores.append(knn.score(X_test, y_test))\n",
    "    print('For k = {}, the KNN Regression score is: {}'.format(k, holdout_scores[k-1]))\n",
    "best_score = max(holdout_scores)\n",
    "best_k = holdout_scores.index(best_score) + 1 #because list indexing starts at 0\n",
    "print(\"\\n (Unweighted) The best k value = {}, with a score of {} \\n\".format(best_k, best_score))\n",
    "\n",
    "# Weighted holdout group testing:\n",
    "print(\"\\n ************** Weighted holdout group testing *********** \\n\")\n",
    "from sklearn.neighbors import KNeighborsRegressor \n",
    "holdout_scores=[] \n",
    "for k in range(1, 20):\n",
    "    knn = KNeighborsRegressor(n_neighbors=k, weights='distance')\n",
    "    knn.fit(X_train,y_train)\n",
    "    y_pred= knn.predict(X_test)\n",
    "    holdout_scores.append(knn.score(X_test, y_test))\n",
    "    print('For k = {}, the KNN Regression score is: {}'.format(k, holdout_scores[k-1]))\n",
    "best_score = max(holdout_scores)\n",
    "best_k = holdout_scores.index(best_score) + 1 #because list indexing starts at 0\n",
    "print(\"\\n (Weighted) The best k value = {}, with a score of {}\".format(best_k, best_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we are using a 10-fold cross validation to test our holdout group results against:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ************** Unweighted holdout group testing *********** \n",
      "\n",
      "For k = 1, the KNN Regression score is: 0.5156852308737754\n",
      "For k = 2, the KNN Regression score is: 0.6222067418204907\n",
      "For k = 3, the KNN Regression score is: 0.649194308446661\n",
      "For k = 4, the KNN Regression score is: 0.6585395349333777\n",
      "For k = 5, the KNN Regression score is: 0.6630676855499151\n",
      "For k = 6, the KNN Regression score is: 0.6648777480638913\n",
      "For k = 7, the KNN Regression score is: 0.6651544496479854\n",
      "For k = 8, the KNN Regression score is: 0.6658201990974189\n",
      "For k = 9, the KNN Regression score is: 0.6654085623469044\n",
      "For k = 10, the KNN Regression score is: 0.6630518190651543\n",
      "For k = 11, the KNN Regression score is: 0.6619254801793324\n",
      "For k = 12, the KNN Regression score is: 0.6602412240426838\n",
      "For k = 13, the KNN Regression score is: 0.6611545409100923\n",
      "For k = 14, the KNN Regression score is: 0.6581734198469871\n",
      "For k = 15, the KNN Regression score is: 0.6555992283292589\n",
      "For k = 16, the KNN Regression score is: 0.6528597339256914\n",
      "For k = 17, the KNN Regression score is: 0.6515809599155544\n",
      "For k = 18, the KNN Regression score is: 0.6505572451647661\n",
      "For k = 19, the KNN Regression score is: 0.6461593096441599\n",
      "\n",
      " (Unweighted) The best k value = 8, with a score of 0.6658201990974189 \n",
      " \n",
      "\n",
      " ************** Weighted holdout group testing *********** \n",
      "\n",
      "For k = 1, the KNN Regression score is: 0.5146264464194366\n",
      "For k = 2, the KNN Regression score is: 0.6221801565259168\n",
      "For k = 3, the KNN Regression score is: 0.6547302345272059\n",
      "For k = 4, the KNN Regression score is: 0.6660356301197595\n",
      "For k = 5, the KNN Regression score is: 0.6737853026883721\n",
      "For k = 6, the KNN Regression score is: 0.6781381775961373\n",
      "For k = 7, the KNN Regression score is: 0.6781359254676994\n",
      "For k = 8, the KNN Regression score is: 0.6793928085766722\n",
      "For k = 9, the KNN Regression score is: 0.6771282358371249\n",
      "For k = 10, the KNN Regression score is: 0.6789602442954406\n",
      "For k = 11, the KNN Regression score is: 0.6795639476326881\n",
      "For k = 12, the KNN Regression score is: 0.679579514984748\n",
      "For k = 13, the KNN Regression score is: 0.680331073720146\n",
      "For k = 14, the KNN Regression score is: 0.6768471524602726\n",
      "For k = 15, the KNN Regression score is: 0.6754260718979548\n",
      "For k = 16, the KNN Regression score is: 0.6748332774941321\n",
      "For k = 17, the KNN Regression score is: 0.6744905040702387\n",
      "For k = 18, the KNN Regression score is: 0.6715739725639465\n",
      "For k = 19, the KNN Regression score is: 0.6700649808407602\n",
      "\n",
      " (Weighted) The best k value = 13, with a score of 0.680331073720146 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Unweighted 10-fold cross validation testing:\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(10, shuffle=True)\n",
    "print(\"\\n ************** Unweighted holdout group testing *********** \\n\")\n",
    "cv_scores=[] \n",
    "for k in range(1, 20):\n",
    "    knn = KNeighborsRegressor(n_neighbors=k)\n",
    "    #knn.fit(X,Y)\n",
    "    #train model with 5 fold cross-validation:\n",
    "    score = cross_val_score(knn, X, Y, cv=kf)\n",
    "    cv_scores.append(score.mean())\n",
    "   \n",
    "    print('For k = {}, the KNN Regression score is: {}'.format(k, score.mean()))\n",
    "best_score = max(cv_scores)\n",
    "best_k = cv_scores.index(best_score) + 1 #because list indexing starts at 0\n",
    "print(\"\\n (Unweighted) The best k value = {}, with a score of {} \\n \".format(best_k, best_score))\n",
    "\n",
    "#  Weighted 10-fold cross validation testing:\n",
    "print(\"\\n ************** Weighted holdout group testing *********** \\n\")\n",
    "\n",
    "cv_scores=[] \n",
    "for k in range(1, 20):\n",
    "    knn = KNeighborsRegressor(n_neighbors=k, weights='distance')\n",
    "    #knn.fit(X,Y)\n",
    "    #train model with 5 fold cross-validation:\n",
    "    score = cross_val_score(knn, X, Y, cv=kf)\n",
    "    cv_scores.append(score.mean())\n",
    "   \n",
    "    print('For k = {}, the KNN Regression score is: {}'.format(k, score.mean()))\n",
    "best_score = max(cv_scores)\n",
    "best_k = cv_scores.index(best_score) + 1 #because list indexing starts at 0\n",
    "print(\"\\n (Weighted) The best k value = {}, with a score of {} \\n\".format(best_k, best_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing - Scaling the features\n",
    "\n",
    "This is helpful to do, because k-nearest neighbors with an Euclidean distance measure is sensitive to magnitudes and hence should be scaled for all features to weigh in equally. \n",
    "\n",
    "We can see if there is a large difference in the scaled model score  vs the unscaled:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "\n",
    "\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Making a train-test split with the scaled features:\n",
    "X_train_s, X_test_s, y_train, y_test = train_test_split(X_scaled, Y, test_size = 0.3, random_state = 465)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " (Unweighted, scaled) The best k value = 2, with a score of 0.8194780266934137 \n",
      "\n",
      "\n",
      " (Weighted, scaled) The best k value = 4, with a score of 0.8357045557401436\n"
     ]
    }
   ],
   "source": [
    "# Unweighted, scaled holdout group testing:\n",
    "from sklearn.neighbors import KNeighborsRegressor \n",
    "holdout_scores=[] \n",
    "for k in range(1, 20):\n",
    "    knn = KNeighborsRegressor(n_neighbors=k)\n",
    "    knn.fit(X_train_s,y_train)\n",
    "    y_pred= knn.predict(X_test_s)\n",
    "    holdout_scores.append(knn.score(X_test_s, y_test))\n",
    "    #print('For k = {}, the KNN Regression score is: {}'.format(k, holdout_scores[k-1]))\n",
    "best_score = max(holdout_scores)\n",
    "best_k = holdout_scores.index(best_score) + 1 #because list indexing starts at 0\n",
    "print(\"\\n (Unweighted, scaled) The best k value = {}, with a score of {} \\n\".format(best_k, best_score))\n",
    "\n",
    "# Weighted holdout group testing:\n",
    "from sklearn.neighbors import KNeighborsRegressor \n",
    "holdout_scores=[] \n",
    "for k in range(1, 20):\n",
    "    knn = KNeighborsRegressor(n_neighbors=k, weights='distance')\n",
    "    knn.fit(X_train_s,y_train)\n",
    "    y_pred= knn.predict(X_test_s)\n",
    "    holdout_scores.append(knn.score(X_test_s, y_test))\n",
    "    #print('For k = {}, the KNN Regression score is: {}'.format(k, holdout_scores[k-1]))\n",
    "best_score = max(holdout_scores)\n",
    "best_k = holdout_scores.index(best_score) + 1 #because list indexing starts at 0\n",
    "print(\"\\n (Weighted, scaled) The best k value = {}, with a score of {}\".format(best_k, best_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the scaled features improve the model accuracy!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " (Unweighted, scaled) The best k value = 2, with a score of 0.8395262991138536 \n",
      " \n",
      "\n",
      " (Weighted, scaled) The best k value = 3, with a score of 0.8542865416104222 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Unweighted 10-fold cross-validation testing: \n",
    "kf = KFold(10, shuffle=True)\n",
    "cv_scores=[] \n",
    "for k in range(1, 10):\n",
    "    knn = KNeighborsRegressor(n_neighbors=k)\n",
    "    #knn.fit(X,Y)\n",
    "    #train model with 10 fold cross-validation:\n",
    "    score = cross_val_score(knn, X_scaled, Y, cv=kf)\n",
    "    cv_scores.append(score.mean())\n",
    "                     \n",
    "best_score = max(cv_scores)\n",
    "best_k = cv_scores.index(best_score) + 1 #because list indexing starts at 0\n",
    "print(\"\\n (Unweighted, scaled) The best k value = {}, with a score of {} \\n \".format(best_k, best_score))\n",
    "\n",
    "#  Weighted 10-fold cross validation testing:\n",
    "cv_scores=[] \n",
    "for k in range(1, 10):\n",
    "    knn = KNeighborsRegressor(n_neighbors=k, weights='distance')\n",
    "    #knn.fit(X,Y)\n",
    "    #train model with 10 fold cross-validation:\n",
    "    score = cross_val_score(knn, X_scaled, Y, cv=kf)\n",
    "    cv_scores.append(score.mean())\n",
    "   \n",
    "\n",
    "best_score = max(cv_scores)\n",
    "best_k = cv_scores.index(best_score) + 1 #because list indexing starts at 0\n",
    "print(\"\\n (Weighted, scaled) The best k value = {}, with a score of {} \\n\".format(best_k, best_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear/OLS Regression\n",
    "\n",
    "We found KNN Regression to yield pretty decent results, with scores of around 0.68 for unscaled features and as good as 0.85 when the features were scaled. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compare KNN Regression's performance, we will run our data through a Linear Regression. Checking linear regression with holdout group and cross-validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: \n",
      " [ 2.46134960e-01 -2.46134960e-01  5.84671406e-05 -5.85022017e-05\n",
      "  5.83175191e-05 -2.24437864e-02  2.25022941e-02  2.25021297e-02\n",
      "  5.85525003e-05  2.09314963e-02  4.15418700e-01  3.70430654e-01\n",
      " -3.55215048e-01  2.25036800e-02  3.13151597e-01 -3.13054605e-01\n",
      " -2.69624160e-01  5.56605085e-02  2.26635553e-01]\n",
      "Intercept: \n",
      " -110.94612996736741\n",
      "R-squared: \n",
      " 0.5187453888778607\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "# Instantiatie the linear model\n",
    "lrm = linear_model.LinearRegression()\n",
    "\n",
    "# Fitting the model to the training data:\n",
    "lrm.fit(X_train, y_train)\n",
    "\n",
    "# Checking the performace of the model:\n",
    "print(\"Coefficients: \\n\", lrm.coef_)\n",
    "print(\"Intercept: \\n\", lrm.intercept_)\n",
    "print(\"R-squared: \\n\", lrm.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: \n",
      " [ 2.45602584e-01 -2.45602584e-01  8.10462756e-05 -8.10806232e-05\n",
      "  8.08829823e-05 -2.06248235e-02  2.07059153e-02  2.07057438e-02\n",
      "  8.11297433e-05  2.08897006e-02  4.11791010e-01  3.95277327e-01\n",
      " -3.40968701e-01  2.07070987e-02  3.05452744e-01 -3.09138167e-01\n",
      " -2.58269595e-01  5.52671687e-02  2.25532374e-01]\n",
      "Intercept: \n",
      " -110.15453386110359\n",
      "R-squared: \n",
      " 0.5194573575705939\n",
      "Cross validation: \n",
      " [0.52885147 0.52112017 0.50415955 0.54927625 0.48751871 0.5352495\n",
      " 0.51737596 0.51455233 0.48691879 0.53776555]\n",
      "Cross validation mean score:  0.5182788301372614\n"
     ]
    }
   ],
   "source": [
    "# Instantiate linear regression model\n",
    "from sklearn import linear_model\n",
    "kf = KFold(10, shuffle=True)\n",
    "lrm = linear_model.LinearRegression()\n",
    "# Fitting the model:\n",
    "lrm.fit(X, Y)\n",
    "\n",
    "# Checking the performace of the model:\n",
    "print(\"Coefficients: \\n\", lrm.coef_)\n",
    "print(\"Intercept: \\n\", lrm.intercept_)\n",
    "print(\"R-squared: \\n\", lrm.score(X, Y))\n",
    "\n",
    "lrm_score = cross_val_score(lrm, X, Y, cv=kf)\n",
    "print('Cross validation: \\n', lrm_score)\n",
    "print('Cross validation mean score: ', lrm_score.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying out Random Forest Regressor on the avocado dataset, just because"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation: \n",
      " [0.85304573 0.89695428 0.89438603 0.87957248 0.87988193 0.87422262\n",
      " 0.88433596 0.88025032 0.87910912 0.87872802]\n",
      "Cross validation mean score:  0.8800486479161342\n"
     ]
    }
   ],
   "source": [
    "# Instantiate linear regression model\n",
    "from sklearn import linear_model\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor()\n",
    "kf = KFold(10, shuffle=True)\n",
    "# Fitting the model:\n",
    "#rf.fit(X, Y)\n",
    "\n",
    "# Checking the performace of the model:\n",
    "# print(\"Coefficients: \\n\", rf.coef_)\n",
    "# print(\"Intercept: \\n\", lrm.intercept_)\n",
    "#print(\"R-squared: \\n\", rf.score(X, Y))\n",
    "\n",
    "rf_score = cross_val_score(rf, X, Y, cv=kf)\n",
    "print('Cross validation: \\n', rf_score)\n",
    "print('Cross validation mean score: ', rf_score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_X_train, A_X_test, A_y_train, A_y_test = train_test_split(X, Y, test_size = 0.3, random_state = 465)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8684794351455949"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestRegressor()\n",
    "\n",
    "rf.fit(A_X_train, A_y_train)\n",
    "\n",
    "A_y_pred = rf.predict(A_X_test)\n",
    "\n",
    "rf.score(A_X_test, A_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like Random Forest actually predicts with better performance than either KNN Regression or Linear Regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Repeating the process with the House Prices Dataset \n",
    "[Kaggle House Prices](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "postgres_user = 'dsbc_student'\n",
    "postgres_pw = '7*.8G9QH21'\n",
    "postgres_host = '142.93.121.174'\n",
    "postgres_port = '5432'\n",
    "postgres_db = 'houseprices'\n",
    "\n",
    "\n",
    "engine = create_engine('postgresql://{}:{}@{}:{}/{}'.format(\n",
    "    postgres_user, postgres_pw, postgres_host, postgres_port, postgres_db))\n",
    "\n",
    "\n",
    "house_prices_df = pd.read_sql_query('select * from houseprices',con=engine)\n",
    "\n",
    "# no need for an open connection, as we're only doing a single query\n",
    "engine.dispose()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# organizing the numerical and non-numerical data:\n",
    "# Numerical features:\n",
    "numerical = house_prices_df.dtypes[house_prices_df.dtypes != \"object\"].index\n",
    "# Non-numerical, categorical features:\n",
    "non_numerical = house_prices_df.dtypes[house_prices_df.dtypes == 'object'].index\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting all the non-numerical features to numerical features:\n",
    "# doing this with one-hot encoding\n",
    "\n",
    "for variable in non_numerical:\n",
    "    house_prices_df = pd.concat([house_prices_df, pd.get_dummies(house_prices_df[variable], prefix=variable, drop_first=True)], axis=1)\n",
    "    \n",
    "# Deleting the original non-numerical feature columns:\n",
    "for variable in non_numerical:\n",
    "    house_prices_df.drop(variable, axis=1, inplace=True)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['saleprice', 'overallqual', 'grlivarea', 'garagecars', 'garagearea',\n",
       "       'totalbsmtsf', 'firstflrsf', 'exterqual_TA', 'fullbath', 'totrmsabvgrd',\n",
       "       'yearbuilt', 'kitchenqual_TA', 'yearremodadd', 'foundation_PConc',\n",
       "       'garageyrblt', 'masvnrarea', 'fireplaces', 'exterqual_Gd',\n",
       "       'bsmtqual_TA', 'bsmtfintype1_GLQ'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding the top 10 most correlated features:\n",
    "\n",
    "np.abs(house_prices_df.corr().loc[:,'saleprice']).sort_values(ascending=False).head(20).index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "del house_prices_df['id']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear/OLS Regression:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear regression, with cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: \n",
      " [ 1.53382906e+04  4.20362837e+01  1.23115461e+04  1.59301312e+01\n",
      "  1.62615854e+01  8.50675312e+00 -3.82181156e+04 -4.52680355e+03\n",
      "  7.49217695e+02  1.80610255e+02 -6.27915695e+03  2.51379452e+02\n",
      "  8.12187097e+02 -6.57976707e+00  2.31488578e+01  1.08982070e+04\n",
      " -3.69735400e+04  8.90591563e+00  1.28921789e+04]\n",
      "Intercept: \n",
      " -847088.1098564983\n",
      "R-squared: \n",
      " 0.7984057228748349\n",
      "Cross validation: \n",
      " [0.80722845 0.84224991 0.83476366 0.84880864 0.76697424 0.86689462\n",
      " 0.11551451 0.85559063 0.83101781 0.77905451]\n",
      "Cross validation mean score: \n",
      " 0.7548096981017245\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    " \n",
    "House_X = house_prices_df[[ 'overallqual', 'grlivarea', 'garagecars', 'garagearea',\n",
    "       'totalbsmtsf', 'firstflrsf', 'exterqual_TA', 'fullbath', 'totrmsabvgrd',\n",
    "       'yearbuilt', 'kitchenqual_TA', 'yearremodadd', 'foundation_PConc',\n",
    "       'garageyrblt', 'masvnrarea', 'fireplaces', 'exterqual_Gd',\n",
    "       'bsmtqual_TA', 'bsmtfintype1_GLQ']]\n",
    "House_X.fillna(0, inplace=True)\n",
    "House_Y = house_prices_df['saleprice']\n",
    "\n",
    "# instantiating the model\n",
    "lrm = linear_model.LinearRegression()\n",
    "# fitting the model:\n",
    "lrm.fit(House_X,House_Y)\n",
    "\n",
    "# Checking the performace of the model:\n",
    "print(\"Coefficients: \\n\", lrm.coef_)\n",
    "print(\"Intercept: \\n\", lrm.intercept_)\n",
    "print(\"R-squared: \\n\", lrm.score(House_X, House_Y))\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(10, shuffle=True)\n",
    "# Cross validation:\n",
    "lrm_score = cross_val_score(lrm, House_X, House_Y, cv=kf)\n",
    "print('Cross validation: \\n', lrm_score)\n",
    "print('Cross validation mean score: \\n', lrm_score.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear regression, with holdout group:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating train test split:\n",
    "House_X_train, House_X_test, House_y_train, House_y_test = train_test_split(House_X, House_Y, test_size = 0.3, random_state = 465)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: \n",
      " [ 1.67182264e+04  3.92077675e+01  1.50064307e+04  6.46538941e+00\n",
      "  1.18672129e+01  8.87004467e+00 -3.76401819e+04 -3.31915754e+03\n",
      "  1.42305299e+03  1.79067589e+02 -5.91775716e+03  1.93696276e+02\n",
      " -6.19989111e+02 -6.82388120e+00  3.30286952e+01  9.69724025e+03\n",
      " -3.41899064e+04  2.26952688e+03  1.27005980e+04]\n",
      "Intercept: \n",
      " -737564.0691899552\n",
      "R-squared: \n",
      " 0.7625249996197485\n"
     ]
    }
   ],
   "source": [
    "# Instantiating the model:\n",
    "lrm = linear_model.LinearRegression()\n",
    "# fitting the model:\n",
    "lrm.fit(House_X_train, House_y_train)\n",
    "# Creating predicitons:\n",
    "lrm.predict(House_X_test)\n",
    "\n",
    "# Checking the performace of the model:\n",
    "print(\"Coefficients: \\n\", lrm.coef_)\n",
    "print(\"Intercept: \\n\", lrm.intercept_)\n",
    "print(\"R-squared: \\n\", lrm.score(House_X_test, House_y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Regression:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the ideal k value for an unweighted KNN Regression model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using holdout method to test our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Unweighted) best k value is 7, with a KNN Regression score of 0.7060147721334012 \n",
      "\n",
      "(Weighted) best k value is 7, with a KNN Regression score of 0.7046018520593789\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor \n",
    "holdout_scores=[] \n",
    "for k in range(1, 20):\n",
    "    knn = KNeighborsRegressor(n_neighbors=k)\n",
    "    knn.fit(House_X_train,House_y_train)\n",
    "    y_pred= knn.predict(House_X_test)\n",
    "    holdout_scores.append(knn.score(House_X_test, House_y_test))\n",
    "#holdout_scores = pd.DataFrame(holdout_scores)\n",
    "#holdout_scores\n",
    "best_score = max(holdout_scores)\n",
    "best_k = holdout_scores.index(best_score) + 1 # because index starts at 0\n",
    "print('(Unweighted) best k value is {}, with a KNN Regression score of {} \\n'.format(best_k, best_score))\n",
    "\n",
    "holdout_scores=[] \n",
    "for k in range(1, 20):\n",
    "    knn = KNeighborsRegressor(n_neighbors=k, weights='distance')\n",
    "    knn.fit(House_X_train,House_y_train)\n",
    "    y_pred= knn.predict(House_X_test)\n",
    "    holdout_scores.append(knn.score(House_X_test, House_y_test))\n",
    "#holdout_scores = pd.DataFrame(holdout_scores)\n",
    "#holdout_scores\n",
    "best_score = max(holdout_scores)\n",
    "best_k = holdout_scores.index(best_score) + 1 # because index starts at 0\n",
    "print('(Weighted) best k value is {}, with a KNN Regression score of {}'.format(best_k, best_score))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross-validation method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Unweighted) best k value is 12, with a KNN Regression score of 0.7370283918123277 \n",
      "\n",
      "(Weighted) best k value is 19, with a KNN Regression score of 0.7444921285601007\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "kf = KFold(10, shuffle=True)\n",
    "# Unweighted Model:\n",
    "\n",
    "cv_scores=[] \n",
    "for k in range(1, 20):\n",
    "    knn = KNeighborsRegressor(n_neighbors=k)\n",
    "    knn.fit(House_X,House_Y)\n",
    "    #train model with 10 fold cross-validation:\n",
    "    score = cross_val_score(knn, House_X, House_Y, cv=kf)\n",
    "    cv_scores.append(score.mean())\n",
    "\n",
    "best_score = max(cv_scores)\n",
    "best_k = cv_scores.index(best_score) + 1 # because index starts at 0\n",
    "print('(Unweighted) best k value is {}, with a KNN Regression score of {} \\n'.format(best_k, best_score))\n",
    "\n",
    "cv_scores=[] \n",
    "for k in range(1, 20):\n",
    "    knn = KNeighborsRegressor(n_neighbors=k, weights='distance')\n",
    "    knn.fit(House_X,House_Y)\n",
    "    #train model with 10 fold cross-validation:\n",
    "    score = cross_val_score(knn, House_X, House_Y, cv=kf)\n",
    "    cv_scores.append(score.mean())\n",
    "\n",
    "best_score = max(cv_scores)\n",
    "best_k = cv_scores.index(best_score) + 1 # because index starts at 0\n",
    "print('(Weighted) best k value is {}, with a KNN Regression score of {}'.format(best_k, best_score))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further validation to check if our best k-value for the nearest neighbor model also has the lowest Root Mean Squared Error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Unweighted) Best k value is 7, with RMSE = 44375.68044130725 \n",
      "\n",
      "(Weighted) Best k value is 7, with RMSE = 44482.18942476738\n"
     ]
    }
   ],
   "source": [
    "# Unweighted KNN model:\n",
    "# testing different k values to see how much error there with each one:\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error\n",
    "errors = []\n",
    "for k in range(1,21):\n",
    "   \n",
    "    model = KNeighborsRegressor(n_neighbors = k)\n",
    "    \n",
    "    model.fit(House_X_train, House_y_train) # Fit them model \n",
    "    House_Y_pred = model.predict(House_X_test) # predicting the model on the test set\n",
    "    \n",
    "    error = (mean_squared_error(House_y_test, House_Y_pred))**0.5 # Calculate RMSE\n",
    "    \n",
    "    errors.append(error) #store rmse values\n",
    "    #print('RMSE value for k= ' , k , 'is:', error)\n",
    "best_rmse = min(errors)\n",
    "best_k = errors.index(best_rmse) + 1\n",
    "print('(Unweighted) Best k value is {}, with RMSE = {} \\n'.format(best_k, best_rmse))\n",
    "\n",
    "# Weighted KNN model:\n",
    "# testing different k values to see how much error there with each one:\n",
    "errors = []\n",
    "for k in range(1,21):\n",
    "   \n",
    "    model = KNeighborsRegressor(n_neighbors = k, weights='distance')\n",
    "    \n",
    "    model.fit(House_X_train, House_y_train) # Fit them model \n",
    "    House_Y_pred = model.predict(House_X_test) # predicting the model on the test set\n",
    "    \n",
    "    error = (mean_squared_error(House_y_test, House_Y_pred))**0.5 # Calculate RMSE\n",
    "    \n",
    "    errors.append(error) #store rmse values\n",
    "    #print('RMSE value for k= ' , k , 'is:', error)\n",
    "best_rmse = min(errors)\n",
    "best_k = errors.index(best_rmse) + 1\n",
    "print('(Weighted) Best k value is {}, with RMSE = {}'.format(best_k, best_rmse))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scaling the feature set to see if KNN yields better results this way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "\n",
    "\n",
    "House_X_scaled = scaler.fit_transform(House_X)\n",
    "House_X_train_scaled = scaler.fit_transform(House_X_train)\n",
    "House_X_test_scaled = scaler.fit_transform(House_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ********* Testing scaled feature set ***************** \n",
      "\n",
      "(Unweighted) best k value is 2, with a KNN Regression score of 0.7520308407614833 \n",
      "\n",
      "(Weighted) best k value is 2, with a KNN Regression score of 0.7592653725069964\n"
     ]
    }
   ],
   "source": [
    "print('\\n ********* Testing scaled feature set ***************** \\n')\n",
    "\n",
    "\n",
    "holdout_scores=[] \n",
    "for k in range(1, 20):\n",
    "    knn = KNeighborsRegressor(n_neighbors=k)\n",
    "    knn.fit(House_X_train_scaled,House_y_train)\n",
    "    House_y_pred= knn.predict(House_X_test_scaled)\n",
    "    holdout_scores.append(knn.score(House_X_test_scaled, House_y_test))\n",
    "#holdout_scores = pd.DataFrame(holdout_scores)\n",
    "#holdout_scores\n",
    "best_score = max(holdout_scores)\n",
    "best_k = holdout_scores.index(best_score) + 1 # because index starts at 0\n",
    "print('(Unweighted) best k value is {}, with a KNN Regression score of {} \\n'.format(best_k, best_score))\n",
    "\n",
    "holdout_scores=[] \n",
    "for k in range(1, 20):\n",
    "    knn = KNeighborsRegressor(n_neighbors=k, weights='distance')\n",
    "    knn.fit(House_X_train_scaled,House_y_train)\n",
    "    House_y_pred= knn.predict(House_X_test_scaled)\n",
    "    holdout_scores.append(knn.score(House_X_test_scaled, House_y_test))\n",
    "#holdout_scores = pd.DataFrame(holdout_scores)\n",
    "#holdout_scores\n",
    "best_score = max(holdout_scores)\n",
    "best_k = holdout_scores.index(best_score) + 1 # because index starts at 0\n",
    "print('(Weighted) best k value is {}, with a KNN Regression score of {}'.format(best_k, best_score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************** Testing scaled feature set, cross-validation *********\n",
      "(Unweighted) best k value is 15, with a KNN Regression score of 0.7502311664988209 \n",
      "\n",
      "(Weighted) best k value is 6, with a KNN Regression score of 0.7644199130878763\n"
     ]
    }
   ],
   "source": [
    "print('*************** Testing scaled feature set, cross-validation *********')\n",
    "# Unweighted Model:\n",
    "kf = KFold(10, shuffle=True)\n",
    "cv_scores=[] \n",
    "for k in range(1, 20):\n",
    "    knn = KNeighborsRegressor(n_neighbors=k)\n",
    "    knn.fit(House_X_scaled,House_Y)\n",
    "    #train model with 10 fold cross-validation:\n",
    "    score = cross_val_score(knn, House_X_scaled, House_Y, cv=kf)\n",
    "    cv_scores.append(score.mean())\n",
    "\n",
    "best_score = max(cv_scores)\n",
    "best_k = cv_scores.index(best_score) + 1 # because index starts at 0\n",
    "print('(Unweighted) best k value is {}, with a KNN Regression score of {} \\n'.format(best_k, best_score))\n",
    "\n",
    "cv_scores=[] \n",
    "for k in range(1, 20):\n",
    "    knn = KNeighborsRegressor(n_neighbors=k, weights='distance')\n",
    "    knn.fit(House_X_scaled,House_Y)\n",
    "    #train model with 10 fold cross-validation:\n",
    "    score = cross_val_score(knn, House_X_scaled, House_Y, cv=kf)\n",
    "    cv_scores.append(score.mean())\n",
    "\n",
    "best_score = max(cv_scores)\n",
    "best_k = cv_scores.index(best_score) + 1 # because index starts at 0\n",
    "print('(Weighted) best k value is {}, with a KNN Regression score of {}'.format(best_k, best_score))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like scaling the features only slightly increased the model's performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
